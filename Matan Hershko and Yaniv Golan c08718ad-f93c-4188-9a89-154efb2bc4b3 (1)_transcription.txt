[19.77 - 19.91] Speaker1: you
[19.91 - 20.00] Speaker2: Hello.
[20.00 - 20.23] Speaker1: you
[21.68 - 22.45] Speaker1: Okay.
[23.75 - 27.23] Speaker2: wow
[27.98 - 29.55] Speaker1: I don't know.
[30.23 - 40.92] Speaker2: um
[41.47 - 42.33] Speaker2: Yeah.
[42.51 - 44.24] Speaker1: Microsoft, by Zoom or by Teams?
[44.60 - 45.74] Speaker2: The Thames.
[45.74 - 47.34] Speaker1: Yeah, it takes a little bit.
[48.47 - 55.20] Speaker2: That's right. So it's also very impressive, right? Big companies and foundations that can't afford to raise a product that's already being raised.
[56.88 - 59.62] Speaker1: And I thought, well, I'm not going to go out there.
[59.73 - 60.48] Speaker2: No, no.
[60.88 - 64.75] Speaker2: What was the experience? I just want to ask you in the video
[62.95 - 63.12] Speaker1: It's like the ocean of life.
[65.22 - 67.08] Speaker1: Yeah.
[67.70 - 71.61] Speaker1: foreign
[72.81 - 80.19] Speaker1: um
[80.48 - 83.58] Speaker1: Okay.
[84.20 - 88.50] Speaker1: foreign
[88.84 - 89.67] Speaker1: Bowser.
[89.05 - 89.58] Speaker2: you
[89.67 - 89.77] Speaker2: you
[90.44 - 90.84] Speaker1: you
[90.62 - 92.41] Speaker2: Yes.
[92.86 - 93.61] Speaker1: No.
[94.03 - 100.00] Speaker2: Okay, okay. Interesting. Especially since the browser is Chrome and not Edge, so it's not that different.
[95.41 - 95.42] Speaker1: you
[100.56 - 103.69] Speaker1: Shanim Shatiskuld Zamaskanabentayim.
[103.69 - 103.83] Speaker2: you
[104.86 - 105.56] Speaker2: Okay.
[105.00 - 105.44] Speaker1: you
[105.56 - 106.05] Speaker1: with help.
[106.70 - 107.81] Speaker2: So,
[108.83 - 110.91] Speaker1: .
[110.91 - 111.42] Speaker2: about on the phone.
[112.27 - 113.06] Speaker2: Each time would be a month.
[112.41 - 112.92] Speaker1: you
[113.78 - 114.56] Speaker1: Yeah.
[115.05 - 115.56] Speaker1: you
[115.25 - 120.06] Speaker2: I wanted to have a long conversation with him last week, and...
[120.41 - 128.06] Speaker2: She does it perfectly.
[126.98 - 127.89] Speaker1: the
[128.38 - 129.78] Speaker1: My match.
[128.53 - 128.97] Speaker2: you
[130.10 - 143.99] Speaker2: Yeah.
[144.26 - 154.78] Speaker2: And I think that it gives more of a specific benefit to this role, most of the skills and capabilities, and we see the impact behind it.
[155.50 - 159.21] Speaker1: foreign
[159.53 - 160.00] Speaker1: Thank you.
[160.00 - 175.44] Speaker2: Right.
[176.04 - 178.76] Speaker2: Yes.
[179.54 - 183.06] Speaker1: um
[183.38 - 185.21] Speaker1: No, it's not easy to manipulate them, not as long as
[185.87 - 189.06] Speaker1: um
[189.32 - 191.06] Speaker1: and to be involved in the political game.
[191.34 - 200.50] Speaker2: Yeah.
[200.78 - 216.04] Speaker2: um
[216.41 - 220.25] Speaker2: um
[220.94 - 222.71] Speaker1: I think it's the first time.
[223.06 - 223.97] Speaker1: you
[223.49 - 223.72] Speaker2: you
[224.16 - 234.03] Speaker2: So I did it in 8.1, I was a senior at the age of 26, and I was there with 30 people. And in the second job at Vectorius, I worked at the Thor's Medical Devices, and I was there for six years.
[234.04 - 237.10] Speaker2: So I started alone, but I realized there are 40 people in your house.
[237.26 - 253.03] Speaker2: um
[253.34 - 264.56] Speaker2: Yeah.
[264.88 - 269.12] Speaker2: And you still see the interaction between people. You say, okay, great, something good happened here.
[269.50 - 270.23] Speaker2: Exactly.
[269.62 - 271.08] Speaker1: It's all that we should be thinking about.
[271.08 - 273.35] Speaker2: Ken, Ken, the Trojano guy from South Africa.
[273.64 - 275.43] Speaker1: Okay, so how many people will you bring to MLB?
[275.85 - 286.20] Speaker2: Yeah.
[286.58 - 288.32] Speaker2: But
[289.06 - 295.25] Speaker2: on
[296.55 - 305.64] Speaker2: .
[306.05 - 310.70] Speaker2: .
[311.26 - 316.37] Speaker2: So there's some kind of convergence point that can be done to change the process.
[316.69 - 321.08] Speaker2: When I don't offer a service, the thing about CRO exists, it's a real thing,
[321.40 - 328.76] Speaker2: The complex point is that it is not observable, not controllable, and it is also not
[329.69 - 337.73] Speaker2: is
[338.12 - 346.50] Speaker2: um
[347.00 - 356.31] Speaker2: He's in the end, he's in the end, yes, no, less than him. He doesn't know what's going on inside of him. He can't change the course of things. He can't change the course of things. Just to stop the time, he's a big idiot.
[356.76 - 359.52] Speaker2: So both of them have less service and it's not a good idea.
[359.88 - 361.00] Speaker2: focuses. Um,
[361.49 - 372.62] Speaker2: And that's where the point of automation can change. It can create a much more reliable, transparent system, easy to use, easy to sell at the price, to do a lot of selling,
[372.99 - 378.43] Speaker2: It's actually very similar to the model that six countries work today, in this way.
[378.81 - 380.44] Speaker2: I'm just going to
[381.00 - 398.11] Speaker2: So at the end, I invite Emil Barri as a great company that changes the game laws of Dacres Biology R&D, because product discovery is one section, food tech is another, tissue engineering is another, all these things we put on the same small basis.
[398.25 - 400.32] Speaker2: to share the set credentials, this is what I
[400.85 - 401.69] Speaker1: level.
[401.94 - 402.64] Speaker2: I'm not sure.
[403.12 - 403.49] Speaker1: you
[403.85 - 411.61] Speaker2: Yeah.
[412.55 - 413.76] Speaker2: Uh,
[414.14 - 419.62] Speaker2: So this is how we see MLBio in the next decade.
[420.08 - 433.61] Speaker2: um
[433.93 - 438.64] Speaker2: credits. So, yeah, it's great, and you can make decisions, and you can make the ability to
[439.49 - 445.79] Speaker2: um
[446.23 - 447.29] Speaker2: There.
[447.85 - 453.05] Speaker1: So what's the way you're going to change the game rules? What's the breakthrough you're going to make?
[453.75 - 466.32] Speaker2: Right.
[466.62 - 472.35] Speaker2: something that in most areas sounds a bit strange, because people think that automation is a big deal,
[472.62 - 479.90] Speaker2: um
[480.37 - 481.50] Speaker2: Uh,
[482.00 - 496.20] Speaker2: And I built also commercial, software and procedural infrastructure.
[496.52 - 505.49] Speaker2: which will enable a significant reduction of automation time and increase reliability and the ability of the users and the customer to
[505.82 - 507.73] Speaker2: There's power in that
[508.08 - 515.75] Speaker2: Israel.
[516.02 - 525.80] Speaker2: which is called payload, because they have a field that sits in the air and is controlled by blood pressure at the left altitude, exactly 0.1 mm2, which is what
[526.16 - 529.16] Speaker2: uh
[529.35 - 538.68] Speaker2: um
[538.80 - 544.62] Speaker2: But to make it possible, there's the non-product development. We created an automation system
[544.99 - 548.07] Speaker2: shlema, kdei levatzea ta kiul, ta bedikot, ta nachkarim
[548.47 - 551.64] Speaker2: Now, that's a lot of things that...
[552.02 - 559.35] Speaker2: And just as an anecdote, when I got to the company, I was an 8-year-old worker. They tried to raise an automation system, it was like 90 million dollars a piece.
[559.61 - 566.16] Speaker2: A month later, I bought an automatic machine that was $1,200 a piece, and instead of $4, it was $10.
[566.40 - 569.83] Speaker2: But long as they're not as cannibalist, I mean, the whole idea of being a
[570.16 - 573.83] Speaker2: .
[574.18 - 577.26] Speaker2: .
[578.42 - 580.75] Speaker2: I think less than a second.
[581.12 - 587.76] Speaker2: um
[588.14 - 597.07] Speaker2: So that's what I did in the past, and that's the component I'm going to do now in MLBio. That is, to re-evaluate, and here I also put a lot of my cooperation as a barrier into the process.
[597.37 - 601.33] Speaker2: l'inconvenient a b'nei b'nei b'nei b'nei b'nei b'nei b'nei b'nei b'nei b'nei b'nei b'nei
[601.40 - 609.59] Speaker2: and instead of doing what everyone is doing right now, which is instead of a head with one head, a head with four, an eight, and a head with a head with a head,
[610.14 - 615.76] Speaker2: To waste a lot of time, to think again about the movement itself that we need to do and to perform it in a different way.
[616.11 - 624.07] Speaker2: I can think of processes where I wrote a provision on the relevant concepts that allow for recognition. I didn't find a patent on this nature.
[624.40 - 627.07] Speaker2: And that means that we can also start from this point.
[627.57 - 628.97] Speaker2: Uh,
[629.54 - 632.61] Speaker2: So that's how we're going to do it. We'll give you an hour.
[632.97 - 642.75] Speaker2: .
[643.25 - 648.85] Speaker2: and a lot of the core is also based on what is called the relationship system between the white and the white, which we know from
[649.16 - 653.54] Speaker2: if I was very strong in the electronic field, I would be very strong in the bio field,
[653.87 - 658.97] Speaker2: Paz Akzara, in 82, who was there for three years and won the Israel Security Council.
[659.38 - 660.66] Speaker2: Uh,
[661.12 - 672.21] Speaker2: DNA, food tech, medical devices, pharma,
[672.54 - 673.73] Speaker2: Colm O'Connor.
[673.87 - 681.71] Speaker2: um
[682.07 - 687.66] Speaker2: and I can be a good candidate. Because that's what always leads to the product and makes the conversations with the biologists
[687.99 - 692.52] Speaker2: and I'm on the side of the, to release those people
[700.76 - 702.85] Speaker1: Okay.
[704.18 - 705.50] Speaker1: .
[706.52 - 713.75] Speaker2: .
[714.02 - 740.99] Speaker2: foreign
[741.21 - 747.21] Speaker2: um
[747.78 - 752.50] Speaker2: Yeah.
[752.92 - 754.95] Speaker2: Right.
[755.35 - 764.76] Speaker2: um
[765.11 - 771.37] Speaker2: foreign
[771.59 - 773.37] Speaker2: Shalom.
[773.12 - 775.71] Speaker1: I'll raise my hand.
[773.61 - 773.75] Speaker2: you
[776.78 - 779.78] Speaker1: .
[780.25 - 781.11] Speaker2: Bioraptor?
[781.50 - 781.97] Speaker1: you
[782.02 - 782.54] Speaker2: you
[783.49 - 787.02] Speaker1: competitive
[787.52 - 788.59] Speaker2: No, it's
[787.83 - 788.00] Speaker1: No, it's
[788.83 - 790.12] Speaker1: Yes.
[790.75 - 792.52] Speaker1: foreign
[792.09 - 792.75] Speaker2: you
[792.88 - 794.23] Speaker1: Yeah.
[794.45 - 794.97] Speaker2: you
[795.09 - 795.14] Speaker2: you
[795.14 - 800.09] Speaker1: One of their capabilities is to identify earlier where the experiment is going.
[795.23 - 795.76] Speaker2: you
[800.33 - 805.64] Speaker2: מדהים. זה כל כך סופר חשוב. דבר שני, לדעתי זה שונה. אני אסביר
[806.16 - 810.78] Speaker2: Because, first of all, I think it's important to look at the future and say,
[811.25 - 818.97] Speaker2: um
[819.42 - 826.47] Speaker2: So in Maccabra 24-7 on cell cultures, the maintenance, the processing, just blocks.
[826.68 - 829.45] Speaker2: Yeah.
[827.47 - 827.62] Speaker1: you
[830.33 - 831.16] Speaker2: Yeah.
[832.68 - 833.61] Speaker2: Bye-bye.
[833.99 - 848.88] Speaker2: Right.
[849.26 - 858.42] Speaker2: And there's a lot of things that I see in general, that there's a lot of potential for cooperation, and other analysis capabilities that have been developed in other places,
[858.73 - 860.68] Speaker2: or
[861.35 - 863.80] Speaker2: or other capabilities of
[864.09 - 874.54] Speaker2: um
[875.11 - 882.04] Speaker1: Yeah.
[882.37 - 889.66] Speaker2: I don't either. I just believe that it could be. There are changes in business that are not in cooperation. There is cooperation for the shop, it's always possible, but it
[889.99 - 900.25] Speaker2: .
[900.78 - 901.14] Speaker1: me.
[901.59 - 902.50] Speaker1: Yeah.
[903.12 - 910.16] Speaker1: .
[910.47 - 917.92] Speaker1: So how is it, Borgen Damien, I understand that you're still at the validation stage, but Borgen Damien, what does the process look like in your world? What are the
[918.30 - 920.45] Speaker1: foreign
[920.92 - 921.97] Speaker2: on the
[922.28 - 926.92] Speaker2: I don't know if it can help, maybe I have the spirit of a customer, John,
[927.23 - 929.95] Speaker2: um
[930.30 - 932.66] Speaker1: .
[932.88 - 934.85] Speaker1: the
[935.07 - 937.18] Speaker2: I knew
[936.47 - 938.25] Speaker1: I knew.
[938.25 - 940.90] Speaker2: Okay.
[940.90 - 943.14] Speaker1: But the format of the particular telephone.
[943.37 - 948.85] Speaker2: No, no, it's something you said in a strange way in the science section.
[949.11 - 957.71] Speaker2: is
[958.87 - 962.28] Speaker1: .
[962.64 - 963.66] Speaker2: Ah.
[965.64 - 966.92] Speaker2: Okay.
[969.52 - 970.73] Speaker2: Yeah.
[971.52 - 972.83] Speaker2: Good.
[973.18 - 976.80] Speaker2: Yeah.
[976.80 - 978.18] Speaker1: um
[978.54 - 978.62] Speaker1: you
[978.62 - 980.30] Speaker2: Right.
[980.68 - 985.76] Speaker2: So we're talking right from the start about how to do the...
[985.99 - 991.59] Speaker2: with
[991.99 - 999.38] Speaker2: um
[1000.26 - 1003.23] Speaker1: .
[1000.45 - 1000.78] Speaker2: you
[1002.99 - 1013.28] Speaker2: No, no, no. On-prem, it will be a very, very specific situation. I mean, I assume that large pharma companies and large hospitals will want it on-prem, but otherwise
[1013.85 - 1017.40] Speaker1: um
[1017.76 - 1025.61] Speaker2: I see it as a good thing in the billing. That is, the solution itself will be the same solution, but I'm going to have to put much more money to companies that do
[1026.12 - 1027.35] Speaker1: Okay.
[1027.98 - 1031.57] Speaker2: um
[1031.87 - 1035.40] Speaker2: um
[1035.70 - 1043.20] Speaker2: We get it automatically to a dispenser, which allows the distribution of the cells into something that looks like a bioserver.
[1043.37 - 1057.12] Speaker2: and divides the cells in a relevant way. The cells are constantly depleted because the original system of cells allows maintenance to the cells and allows them to live in a regular way. Already about 20% of the work is in biological works and the main source of pollution.
[1057.31 - 1066.29] Speaker2: which are about 30% of the cases, and the worst thing is that they are done at random. So there are companies that have signed a half-year-old ban.
[1066.64 - 1070.31] Speaker2: NetRig Al-Zium, which is basically the carpet for the incubator,
[1070.62 - 1075.37] Speaker2: and there are other companies that just, like, in a regular way, they're with two months a year.
[1075.38 - 1076.68] Speaker2: No.
[1076.81 - 1078.22] Speaker1: And why is it your opinion?
[1078.66 - 1080.68] Speaker2: Help me, Adam. Help me, Adam.
[1081.44 - 1081.94] Speaker1: you
[1082.62 - 1095.46] Speaker2: So basically, we have a system like this, and we allow the researcher to regularly, 24-7, to view and be able to evaluate the experiment, which allows him to guide exactly like the rest of the laboratory.
[1095.79 - 1101.14] Speaker2: Shalom.
[1101.35 - 1104.94] Speaker2: Temperatural or whatever, you know, it's both and then.
[1105.62 - 1107.74] Speaker2: Mashigam.
[1108.16 - 1110.68] Speaker2: And in the end, we're going to have
[1110.11 - 1114.83] Speaker1: um
[1115.14 - 1119.40] Speaker2: I can, and as soon as I do it, I'll expose it to the
[1119.72 - 1126.07] Speaker2: You think that the situation I'm in is 24-7, I can go and fight it. And every time I go out, the destruction is actually a piece of the plan.
[1126.46 - 1135.64] Speaker2: So, it's a bit more convenient. The process in which I take a sample of the status in the brain, is I take my plastic or my multi-weather, I put it in my brain.
[1134.79 - 1138.94] Speaker1: um
[1139.14 - 1166.59] Speaker2: or
[1166.90 - 1168.27] Speaker2: Okay.
[1167.16 - 1174.18] Speaker1: So why can you do it without robotic sound? How do you do it without having to use this high-tech technology?
[1174.51 - 1190.64] Speaker2: .
[1192.96 - 1193.31] Speaker1: .
[1194.01 - 1201.16] Speaker2: And that's true for all the solutions we've seen, except for one that was really cool, which uses lasers.
[1201.48 - 1205.77] Speaker2: um
[1206.14 - 1211.77] Speaker2: to very specific things. To single-cell manipulation and not to things that require
[1212.12 - 1213.05] Speaker2: about anything fit.
[1213.90 - 1214.98] Speaker2: Yeah.
[1214.12 - 1214.16] Speaker1: you
[1215.55 - 1218.12] Speaker2: as... I can say what she did, really.
[1217.46 - 1217.72] Speaker1: you
[1218.12 - 1222.16] Speaker1: It's a flexibility that I have
[1222.27 - 1225.64] Speaker1: .
[1226.22 - 1229.18] Speaker1: .
[1229.72 - 1230.29] Speaker1: plan
[1230.74 - 1242.31] Speaker2: So part of the point is that, this is the interesting part of the story, because the basic building blocks, which allows you to move minimally, which is basically the inspection and control of the users in a certain way,
[1242.72 - 1256.77] Speaker2: um
[1257.09 - 1258.09] Speaker2: This is a hot...
[1258.51 - 1263.79] Speaker2: Yesh Deir Echad, to check the reality, that what we're saying is that it's constantly being opposed to the end of the spectrum,
[1264.05 - 1268.94] Speaker2: foreign
[1269.31 - 1280.66] Speaker2: So there's a way of rethinking of things. If we're going to make a long-term, we're all going to use centrifugal methods to make a lot of fat. And there are many ways to do that. We're going to do it in a different way, which is more scalable, more flexible, more
[1280.77 - 1285.83] Speaker2: So there's an issue here, not necessarily of another kind of development, but of a digital development.
[1285.87 - 1288.90] Speaker2: And that's also one of the reasons we want to present it as
[1289.11 - 1294.07] Speaker2: We want to put a screen of the glass of ice in front of the researchers and say, listen, we want you to guess
[1294.37 - 1298.64] Speaker2: um
[1299.62 - 1302.14] Speaker2: And it's less important to them how we do it.
[1302.37 - 1309.11] Speaker2: And it's really something that we've seen, because we're really interested in validation. For example, we talked to Dan Dominesoni from Shiba, if you know him by chance.
[1309.48 - 1311.16] Speaker2: uh
[1311.70 - 1320.05] Speaker2: It was an amazing conversation. It was a really fun conversation. We have a continuation of the conversation. If you want to sign up for our cooperation, we have conversations with them.
[1320.40 - 1322.07] Speaker2: and the design problems
[1322.37 - 1325.27] Speaker2: And they're like,
[1326.12 - 1334.09] Speaker2: .
[1334.37 - 1335.07] Speaker2: made up.
[1337.81 - 1338.16] Speaker1: Good.
[1339.16 - 1340.81] Speaker1: Right.
[1341.38 - 1346.72] Speaker1: .
[1347.03 - 1348.66] Speaker2: Yeah.
[1349.42 - 1349.83] Speaker1: you
[1349.62 - 1354.44] Speaker2: Yeah.
[1355.05 - 1356.61] Speaker1: Okay.
[1357.09 - 1359.44] Speaker1: um
[1360.46 - 1362.85] Speaker1: is
[1363.35 - 1363.57] Speaker2: you
[1363.57 - 1364.31] Speaker1: Yeah.
[1365.14 - 1372.18] Speaker1: Okay.
[1371.87 - 1372.12] Speaker2: Yeah. Okay.
[1372.18 - 1372.40] Speaker2: you
[1372.51 - 1372.94] Speaker2: you
[1372.94 - 1375.16] Speaker1: How much rejection did you get in the meantime?
[1376.42 - 1382.90] Speaker2: So the rejectives that I received, in a certain extent, are a bit of an issue of, let's call it,
[1383.44 - 1390.40] Speaker2: Okay.
[1390.81 - 1402.31] Speaker2: um
[1402.40 - 1414.33] Speaker2: foreign
[1414.57 - 1426.09] Speaker2: um
[1426.61 - 1431.61] Speaker2: um
[1432.11 - 1446.79] Speaker2: um
[1447.24 - 1451.20] Speaker2: After half an hour, he came out with his leg in between his legs and realized he couldn't break my leg.
[1451.37 - 1454.55] Speaker2: But was it the guy? I'm also not sure.
[1454.98 - 1465.83] Speaker2: Right.
[1469.03 - 1469.44] Speaker1: you
[1470.81 - 1472.18] Speaker1: Okay.
[1472.98 - 1491.05] Speaker2: AI.
[1491.33 - 1494.35] Speaker2: and Shiva, who is also very interested in the Talmud.
[1494.59 - 1503.66] Speaker2: is
[1504.07 - 1505.66] Speaker2: Yeah.
[1506.22 - 1511.05] Speaker2: So to start working in a way that's more like it, after the training and the strength of the person, I have about
[1511.40 - 1516.61] Speaker2: I
[1516.96 - 1523.03] Speaker2: So as soon as there is money in the bank, in good direction, we put their documents and they are inside us for 30 days.
[1523.46 - 1524.83] Speaker2: Uh,
[1525.22 - 1535.31] Speaker2: .
[1535.62 - 1538.35] Speaker2: Gamut Shop Double Regional,
[1538.48 - 1542.14] Speaker2: uh
[1542.14 - 1543.05] Speaker1: Yeah.
[1542.44 - 1543.09] Speaker2: Yeah.
[1543.09 - 1543.24] Speaker1: you
[1543.81 - 1544.14] Speaker2: Well,
[1544.61 - 1545.74] Speaker1: Yeah.
[1546.20 - 1548.87] Speaker2: Is that what it is?
[1549.66 - 1556.94] Speaker2: Yeah.
[1557.01 - 1565.12] Speaker2: It started with a specific device, then it went to stem cell therapy, then to post-traumatic medicine, and so on until it ended at this point.
[1565.46 - 1580.62] Speaker2: It's a lot of conversations with people, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations, with organizations,
[1582.92 - 1585.79] Speaker1: .
[1589.35 - 1591.27] Speaker1: .
[1592.18 - 1611.70] Speaker2: Yeah.
[1612.12 - 1620.07] Speaker2: It's the large pharma companies that are taking it out of there because they have the money and they don't care to distribute it, because one of the things that is important to them is money, more than anything else.
[1620.46 - 1625.81] Speaker2: But all the small companies in the United States have their own
[1626.24 - 1638.59] Speaker2: is
[1639.31 - 1646.11] Speaker2: It's a full-scale research that is worth a lot of money, both in the field of personal health and in the field of biological research.
[1646.51 - 1651.37] Speaker2: which doesn't exist, right? So the perception is that there's an enabler here, in a way,
[1651.70 - 1657.42] Speaker2: a
[1657.94 - 1661.64] Speaker1: foreign
[1662.33 - 1664.14] Speaker1: foreign
[1664.53 - 1666.46] Speaker1: Yes.
[1666.72 - 1667.09] Speaker2: Yeah.
[1667.38 - 1669.24] Speaker1: Let's wait for it. In 15 years,
[1669.40 - 1669.90] Speaker2: you
[1670.14 - 1671.77] Speaker1: Yes.
[1672.66 - 1674.64] Speaker2: Yeshua
[1674.90 - 1681.01] Speaker2: FD8
[1682.61 - 1694.62] Speaker2: um
[1694.87 - 1699.70] Speaker2: The statistic is that 97% of the compounds that work on the receptors don't work.
[1695.03 - 1695.35] Speaker1: you
[1700.29 - 1704.18] Speaker2: um
[1704.79 - 1716.57] Speaker2: um
[1716.66 - 1720.55] Speaker2: that contains a large amount of food, and it's really a small piece
[1721.07 - 1724.83] Speaker2: And then all the other people say that the image is much bigger.
[1725.11 - 1731.31] Speaker2: Because it's really a small piece of human brain. And then the mechanism of the action, how the body works, is much clearer and more clear.
[1731.62 - 1737.48] Speaker2: And what FDR says is, put an end to the absurdity of certain vivo, it doesn't work. It's not magical.
[1737.81 - 1739.11] Speaker2: Let's move on to the organoids.
[1739.59 - 1743.81] Speaker2: And he's already in a situation where today, if you have a component that is proven to be
[1744.48 - 1750.92] Speaker2: and you've shown that he works on an organoid, you can send him to a human without any
[1751.57 - 1753.92] Speaker2: the
[1754.33 - 1759.88] Speaker2: So,
[1760.20 - 1765.05] Speaker2: which comes with about 20% in vitro and 80% in vivo, it will turn.
[1765.61 - 1768.85] Speaker2: 90% of people will die.
[1769.14 - 1773.38] Speaker2: So not only will there be more wetlands,
[1773.68 - 1778.03] Speaker2: And my hope is that most of the wet labs in the small companies will not be on-prem.
[1778.42 - 1780.98] Speaker2: Yes.
[1781.85 - 1784.46] Speaker1: .
[1784.55 - 1787.35] Speaker1: Thank you.
[1788.12 - 1793.74] Speaker1: which I try to predict ahead of time what works and what doesn't.
[1794.29 - 1797.37] Speaker1: um
[1798.44 - 1803.38] Speaker1: .
[1804.22 - 1806.83] Speaker2: is
[1806.18 - 1806.55] Speaker1: you
[1806.83 - 1808.44] Speaker1: No,
[1806.90 - 1807.38] Speaker2: Right?
[1808.11 - 1825.70] Speaker2: Right.
[1826.18 - 1830.62] Speaker2: And over time we find that the hard things aren't as hard as chaos and chaos.
[1830.81 - 1832.12] Speaker2: which is a little more important.
[1832.42 - 1835.24] Speaker2: And the things that are empty are not always empty. There are things that are more...
[1835.72 - 1839.31] Speaker2: But you have a lot of friends who are really chaos.
[1839.64 - 1843.83] Speaker2: Shoney is very, very important. The two parts are very,
[1843.90 - 1859.77] Speaker2: and there's just no ability to make a prediction. But on the other hand, if we're talking about experts in this field, people who have done this, they think it's impossible. They think there's no doubt that there's a lot of value in the in silico. He's using the funnel in a very,
[1860.01 - 1866.31] Speaker2: But the observation ability that I have lost, the ability of the simulation that I have lost, that made it difficult for us to build the model,
[1866.77 - 1873.46] Speaker2: And that's actually part of the psychological loss, because it's also very happy to put everyone between my eyes during the period of the problem.
[1873.79 - 1878.33] Speaker2: Yeah.
[1878.77 - 1879.74] Speaker2: Yeah.
[1879.31 - 1879.51] Speaker1: you
[1879.74 - 1885.38] Speaker1: um
[1885.57 - 1886.66] Speaker2: Yeah, I know.
[1887.29 - 1887.64] Speaker1: you
[1888.64 - 1889.35] Speaker1: eh,
[1890.85 - 1891.77] Speaker1: the
[1891.98 - 1894.88] Speaker1: .
[1895.51 - 1896.40] Speaker2: Amish.
[1898.18 - 1900.83] Speaker1: And what will you get?
[1901.29 - 1915.72] Speaker2: um
[1914.94 - 1917.01] Speaker1: What you see today...
[1918.35 - 1920.37] Speaker1: .
[1920.37 - 1920.66] Speaker2: you
[1920.81 - 1951.11] Speaker2: What?
[1942.14 - 1942.24] Speaker1: you
[1951.42 - 1955.68] Speaker2: And it's a service that already today, they're paying between half a million to a million.
[1956.31 - 1958.57] Speaker2: Right.
[1960.09 - 1962.61] Speaker1: um
[1963.20 - 1972.66] Speaker2: So what's happening today, for all intents and purposes, we're talking specifically about the sartanic, because it's the easiest and best solution in this process. We're taking an example from the Great and the Great.
[1972.98 - 1989.70] Speaker2: is
[1981.22 - 1981.40] Speaker1: you
[1990.12 - 1990.64] Speaker2: you
[1991.12 - 2000.77] Speaker2: .
[2000.96 - 2013.09] Speaker2: It's a new value or not a new value. We will, in a way, make some drugs that are healthy.
[2013.57 - 2017.62] Speaker2: It's a long time since I discovered that certain drugs for epilepsy are
[2020.85 - 2027.14] Speaker2: So that's kind of the random phase that helps us in this process, because we don't have idle time for machines. We can just always develop compounds.
[2028.29 - 2032.81] Speaker1: Why do you need two working systems? You're a service, you don't know how many systems
[2033.27 - 2047.61] Speaker2: um
[2048.05 - 2056.62] Speaker2: is
[2056.86 - 2063.51] Speaker2: .
[2066.28 - 2071.16] Speaker1: .
[2071.91 - 2073.91] Speaker1: um
[2074.66 - 2075.91] Speaker1: No shit.
[2076.39 - 2085.80] Speaker2: Right.
[2084.61 - 2089.20] Speaker1: Yeah.
[2089.64 - 2093.55] Speaker1: is
[2092.11 - 2092.36] Speaker2: you
[2093.68 - 2107.99] Speaker2: um
[2107.18 - 2108.64] Speaker1: Thank you.
[2108.89 - 2112.66] Speaker2: service.
[2112.12 - 2112.36] Speaker1: you
[2112.66 - 2115.57] Speaker1: But I'll say it again. I don't want to get too much into it,
[2115.68 - 2118.26] Speaker2: service service no time for service and it's not a
[2117.41 - 2118.84] Speaker1: Absolutely.
[2119.07 - 2119.45] Speaker2: you
[2119.70 - 2121.09] Speaker1: Wow.
[2121.09 - 2129.14] Speaker2: Right.
[2129.49 - 2130.93] Speaker2: So the film
[2131.32 - 2137.62] Speaker2: um
[2137.91 - 2139.74] Speaker2: is
[2140.99 - 2146.53] Speaker2: That means, even in this situation, this machine can call it a top service for processes that are
[2147.22 - 2149.72] Speaker2: I just want to make sure that at all levels
[2153.24 - 2154.99] Speaker1: Okay.
[2156.26 - 2158.16] Speaker1: as
[2158.72 - 2159.70] Speaker1: fish
[2160.57 - 2161.32] Speaker2: I don't know.
[2161.61 - 2162.05] Speaker1: Okay.
[2162.22 - 2171.26] Speaker2: Right.
[2171.41 - 2179.66] Speaker2: um
[2180.18 - 2184.24] Speaker2: foreign
[2184.95 - 2187.11] Speaker2: and really scale up the network.
[2192.43 - 2194.14] Speaker1: I
[2194.89 - 2209.55] Speaker2: I would love to have relevant design partners. I might close a few small and specific businesses to see if there is any kind of revenue. I would like a pipeline that is able to receive the service within the process. I am ready to read the accounts
[2209.91 - 2221.36] Speaker2: um
[2221.36 - 2225.89] Speaker1: foreign
[2226.91 - 2243.66] Speaker2: So,
[2243.16 - 2244.32] Speaker1: Like, I'm a little bit scared.
[2245.09 - 2248.59] Speaker1: .
[2249.11 - 2255.49] Speaker1: foreign
[2255.03 - 2255.72] Speaker2: you
[2255.93 - 2260.11] Speaker2: You're right. There's also this idea of, let's call it...
[2260.12 - 2270.97] Speaker2: Shoney Benolamot, Shieyem Ainein Lirot Oto. Ki im karega, Rom Meshki Mishimu Ehez Zajeneralistim, Kade L'Avim Ta Hazon Zat Fisa, Meshki Hayay Hayab Niyot Bo Mishuk, Neyam Mishimu Pachot Echad Me Meshki,
[2271.30 - 2284.89] Speaker2: This is the language that is really used in medical science.
[2285.32 - 2291.89] Speaker2: um
[2292.26 - 2307.76] Speaker2: And also there, it's a question of which investment they have. There's a difference between talking to Pfizer, Merck, or investment firms in this way, and talking to them in a different way during this process. But even if I had to talk to AliveBC, which is an investment that entered the A-RAM, they would have talked about revenue that was there,
[2307.86 - 2310.74] Speaker2: Now, revenue of $3 million is $3.2 billion.
[2311.62 - 2317.59] Speaker2: is
[2317.86 - 2319.24] Speaker1: .
[2319.91 - 2320.28] Speaker2: I
[2320.70 - 2327.51] Speaker2: Shela, I can tell you that we talk about three businesses of choice, like Crown Barrier, we both understand that it doesn't raise the price.
[2328.30 - 2328.80] Speaker1: you
[2328.43 - 2332.76] Speaker2: It's to create a specific service and a specific lock that I can close in front of
[2333.93 - 2337.72] Speaker1: foreign
[2338.32 - 2341.14] Speaker1: .
[2342.01 - 2342.61] Speaker1: you
[2343.09 - 2345.76] Speaker1: um
[2346.76 - 2347.59] Speaker1: Okay.
[2347.99 - 2350.41] Speaker2: You say. It's a good question. What do you think? What do you think?
[2351.68 - 2355.68] Speaker1: um
[2356.24 - 2360.22] Speaker1: um
[2361.43 - 2368.41] Speaker1: um
[2367.93 - 2368.26] Speaker2: the president.
[2369.09 - 2369.72] Speaker1: you
[2370.41 - 2374.51] Speaker1: I think that what you have to miss in my case is that it's much more important
[2374.97 - 2376.39] Speaker1: is
[2377.86 - 2380.64] Speaker1: See ya.
[2381.41 - 2381.82] Speaker1: you
[2382.53 - 2385.57] Speaker1: .
[2385.80 - 2385.89] Speaker1: you
[2385.89 - 2386.16] Speaker2: Good.
[2386.16 - 2386.22] Speaker1: you
[2386.43 - 2391.89] Speaker1: Yes, you're in a very backward situation where you need a little more money.
[2392.45 - 2393.64] Speaker1: That's a gumbo.
[2394.09 - 2394.51] Speaker2: you
[2394.66 - 2397.95] Speaker1: Yeah.
[2398.36 - 2400.86] Speaker1: Hi.
[2398.66 - 2399.11] Speaker2: Right.
[2401.05 - 2401.53] Speaker2: you
[2401.53 - 2406.05] Speaker1: Right.
[2406.64 - 2410.53] Speaker1: I mean, you put the needle on the side, the chance is that you just don't get it, right?
[2411.03 - 2413.70] Speaker1: my source is the intermediate funding
[2413.20 - 2413.43] Speaker2: you
[2414.64 - 2418.55] Speaker1: to under-promise and overachieve.
[2419.30 - 2423.66] Speaker1: um
[2424.09 - 2425.26] Speaker1: Yes.
[2426.01 - 2427.91] Speaker2: in the wind.
[2427.49 - 2430.30] Speaker1: .
[2430.76 - 2432.70] Speaker1: Yeah.
[2433.16 - 2433.59] Speaker1: you
[2434.89 - 2439.93] Speaker1: You can do multiple ways.
[2436.36 - 2436.78] Speaker2: you
[2440.20 - 2441.68] Speaker1: That I'm besotted.
[2441.97 - 2443.24] Speaker1: Please see it.
[2443.62 - 2444.62] Speaker1: him.
[2445.41 - 2452.86] Speaker1: C, the seed extension, all these processes allow us to have much better accuracy. They are less visible as a failure, let's call it that.
[2453.78 - 2454.41] Speaker1: Okay.
[2454.45 - 2457.76] Speaker1: But I think what's really important is
[2454.76 - 2455.20] Speaker2: do.
[2458.24 - 2466.34] Speaker1: um
[2462.45 - 2462.91] Speaker2: you
[2466.93 - 2468.74] Speaker1: I don't wish to move on
[2468.99 - 2471.80] Speaker1: promising
[2472.05 - 2472.34] Speaker1: you
[2472.72 - 2474.66] Speaker1: Yeah.
[2476.11 - 2483.78] Speaker1: and good alignment, and that puts you in a good place. But I mainly want to hear from them what they expect to see in the
[2484.36 - 2484.99] Speaker2: you
[2485.68 - 2486.95] Speaker2: Yeah.
[2486.95 - 2490.16] Speaker1: is
[2490.53 - 2493.74] Speaker1: .
[2494.22 - 2502.41] Speaker2: I can tell you that what I heard from the people I got to, like at IDC, who are more specific in their
[2502.70 - 2504.53] Speaker2: .
[2505.01 - 2509.34] Speaker2: So
[2509.95 - 2510.84] Speaker2: That's it?
[2511.01 - 2520.70] Speaker2: parma and medical device
[2520.89 - 2520.91] Speaker2: you
[2520.91 - 2521.16] Speaker1: is better.
[2521.16 - 2524.28] Speaker2: And that's really kind of why it's much louder than it is at the USA.
[2521.22 - 2521.26] Speaker1: you
[2524.57 - 2531.82] Speaker2: you don't have anything other than a device that is in some kind of a cold body and does something. You don't prove any serious injuries or anything.
[2532.26 - 2536.47] Speaker2: safety
[2536.89 - 2541.59] Speaker2: And so what I talked to companies that are more related to the field is the idea
[2541.80 - 2547.09] Speaker2: The perspective of the mechanism is that it's a retrospective of one.
[2547.20 - 2551.59] Speaker2: You're talking for a while, the technology is very interesting, it looks relevant, we want to see
[2552.43 - 2553.80] Speaker1: Yeah.
[2555.28 - 2559.47] Speaker1: um
[2559.95 - 2561.24] Speaker1: um
[2561.53 - 2561.55] Speaker1: you
[2561.55 - 2561.66] Speaker2: you
[2561.66 - 2564.47] Speaker1: the whole piece. It is
[2561.70 - 2561.91] Speaker2: you
[2564.93 - 2565.47] Speaker2: Yeah.
[2565.47 - 2568.49] Speaker1: Yes, you can put two of them on one side, and the second point needs to be
[2568.95 - 2571.64] Speaker1: is
[2571.64 - 2572.36] Speaker2: Shalom.
[2571.66 - 2572.12] Speaker1: Shalom.
[2572.86 - 2573.51] Speaker2: there.
[2573.64 - 2574.16] Speaker1: Okay.
[2574.26 - 2579.93] Speaker1: You can play the game, but most of the people
[2577.93 - 2578.22] Speaker2: played the game kind of a
[2580.51 - 2582.24] Speaker1: So from a general standpoint,
[2582.95 - 2589.18] Speaker1: might want to actually acquire you, and they need to know that they're acquiring an asset, and not a project, and they don't want to invest in R&D.
[2589.43 - 2589.86] Speaker2: you
[2590.12 - 2590.59] Speaker1: you
[2590.74 - 2593.01] Speaker1: which is fine as an option, but not as a plan.
[2593.89 - 2594.59] Speaker1: And
[2594.68 - 2595.16] Speaker2: That's okay.
[2596.14 - 2596.84] Speaker1: you
[2597.30 - 2598.95] Speaker1: Um,
[2599.39 - 2601.22] Speaker1: foreign
[2602.30 - 2616.93] Speaker2: um
[2617.62 - 2624.01] Speaker2: To the leader.
[2624.18 - 2630.51] Speaker2: And for that I need this fund. Because if I now raise a million dollars, two million dollars, which I already have,
[2630.89 - 2642.66] Speaker2: um
[2642.97 - 2649.89] Speaker2: You understand? Because we're talking about some machine, and I'm still not there. That's my fear. The price.
[2650.36 - 2654.47] Speaker2: uh
[2654.91 - 2656.39] Speaker2: um
[2657.36 - 2660.89] Speaker2: So that's my thoughts and concerns
[2661.09 - 2668.36] Speaker2: So first of all, I'll try your thoughts. It's another thing to know, to keep your thoughts, to see what you're doing and to see what you're doing.
[2670.84 - 2672.70] Speaker1: Thank you very much.
[2673.51 - 2684.91] Speaker2: So if we're talking about the first market, it's $1.5 billion. The market we're continuing on is $66 billion, and we're constantly receiving feedback that we're missing about the same amount.
[2685.30 - 2689.16] Speaker2: שזה הגיוני כי שוק הפרמה כלל הוא 2.4 טריליון דולר
[2689.55 - 2700.84] Speaker2: and the food market is 400 trillion dollars. So the numbers we get are a little bit small, the market movements are small, but I recommend again to underprivileged
[2702.05 - 2702.36] Speaker1: you
[2704.82 - 2710.14] Speaker1: um
[2711.30 - 2715.32] Speaker1: um
[2716.07 - 2716.76] Speaker1: you
[2718.28 - 2722.74] Speaker1: foreign
[2723.11 - 2723.30] Speaker1: you
[2723.64 - 2724.34] Speaker1: Mm-hmm.
[2726.89 - 2728.01] Speaker1: I think it's possible.
[2728.34 - 2729.14] Speaker1: and
[2731.76 - 2736.97] Speaker1: .
[2737.53 - 2741.66] Speaker1: um
[2743.34 - 2747.14] Speaker1: um
[2745.74 - 2746.07] Speaker2: Yeah.
[2747.28 - 2747.78] Speaker1: you
[2747.93 - 2749.26] Speaker1: And that's because
[2749.51 - 2751.80] Speaker1: is
[2751.84 - 2753.36] Speaker1: to
[2754.16 - 2757.36] Speaker1: science
[2757.78 - 2762.03] Speaker1: .
[2762.12 - 2766.39] Speaker1: foreign
[2766.61 - 2772.76] Speaker1: um
[2766.89 - 2766.97] Speaker2: you
[2773.49 - 2777.78] Speaker1: Not very much. Both robotics and DeeperTech.
[2778.12 - 2781.74] Speaker1: .
[2782.07 - 2783.16] Speaker1: Amen.
[2783.61 - 2791.47] Speaker1: First meeting.
[2791.78 - 2794.82] Speaker1: Yeah.
[2792.09 - 2792.11] Speaker2: you
[2795.93 - 2797.66] Speaker1: um
[2797.89 - 2803.61] Speaker1: um
[2798.16 - 2798.32] Speaker2: you
[2802.34 - 2802.43] Speaker2: you
[2804.20 - 2804.80] Speaker1: you
[2806.07 - 2813.86] Speaker1: But I'll give them... You know, I don't even know if I'll give them anything. I think it's better to just think about it before you get to the point.
[2814.80 - 2819.76] Speaker1: .
[2821.51 - 2822.26] Speaker1: And
[2822.57 - 2826.55] Speaker1: um
[2825.43 - 2825.61] Speaker2: you
[2827.49 - 2829.78] Speaker1: raising your A successfully
[2829.57 - 2829.64] Speaker2: you
[2829.78 - 2829.89] Speaker2: you
[2830.24 - 2834.78] Speaker1: um
[2835.18 - 2839.70] Speaker1: um
[2839.70 - 2840.07] Speaker2: I don't see anything on the screen.
[2840.26 - 2841.12] Speaker1: the achievable
[2841.41 - 2841.72] Speaker2: you
[2841.72 - 2849.11] Speaker1: Yes.
[2849.32 - 2849.86] Speaker2: you
[2850.36 - 2854.70] Speaker1: .
[2854.14 - 2857.34] Speaker2: I'm very happy with the connection. It seems very relevant to me.
[2857.68 - 2862.01] Speaker1: Just a lot of shots that were explained that maybe it's enough to...
[2862.84 - 2867.99] Speaker1: You will probably be dealing with similar challenges, or even more challenging challenges, by the way.
[2868.30 - 2868.82] Speaker2: you
[2868.82 - 2869.43] Speaker1: Yeah.
[2869.09 - 2876.36] Speaker2: um
[2876.45 - 2894.59] Speaker2: um
[2894.89 - 2896.26] Speaker2: But you can do
[2895.24 - 2897.74] Speaker1: I have an idea.
[2898.28 - 2902.41] Speaker1: um
[2902.41 - 2902.64] Speaker2: you
[2902.64 - 2902.72] Speaker1: you
[2902.78 - 2906.72] Speaker1: After you do this, the chances are 40%. Right now, when
[2905.07 - 2905.49] Speaker2: you
[2907.12 - 2909.09] Speaker1: much much less than that, okay?
[2908.62 - 2908.74] Speaker2: you
[2909.36 - 2913.64] Speaker1: um
[2914.47 - 2915.20] Speaker1: But it
[2915.51 - 2916.09] Speaker1: Please.
[2916.22 - 2918.55] Speaker1: You know what I'm saying?
[2918.03 - 2918.36] Speaker2: you
[2919.03 - 2921.18] Speaker1: foreign
[2921.62 - 2921.82] Speaker2: you
[2921.82 - 2926.59] Speaker1: .
[2921.86 - 2922.12] Speaker2: rolling.
[2926.70 - 2926.72] Speaker1: you
[2926.72 - 2936.47] Speaker2: Yeah.
[2926.86 - 2927.20] Speaker1: No,
[2936.51 - 2938.28] Speaker2: Wow.
[2936.74 - 2937.20] Speaker1: Boom.
[2938.16 - 2942.03] Speaker1: foreign
[2942.36 - 2944.84] Speaker1: Yes.
[2944.99 - 2945.28] Speaker2: Yeah.
[2945.28 - 2949.01] Speaker1: foreign
[2945.32 - 2946.09] Speaker2: That's a bit too early.
[2949.41 - 2949.89] Speaker2: you
[2949.89 - 2956.55] Speaker1: .
[2956.97 - 2957.61] Speaker1: Tata Katot!
[2958.12 - 2962.55] Speaker1: First of all, it's the good of society. First of all, our good and your good as well.
[2962.39 - 2962.97] Speaker2: you
[2963.14 - 2963.32] Speaker2: you
[2963.32 - 2963.66] Speaker1: you
[2963.36 - 2967.39] Speaker2: um
[2967.89 - 2974.70] Speaker1: So we're going to do it this way, and only after the social welfare is over can we talk about the welfare of the government, the welfare of the economy,
[2975.07 - 2978.34] Speaker1: .
[2979.26 - 2980.14] Speaker1: Um,
[2980.99 - 2985.93] Speaker1: Okay. So I, if you want, I'll check with the B.Y. CEO if he's ready to
[2985.93 - 2987.09] Speaker2: I would love to.
[2987.89 - 2993.84] Speaker1: um
[2994.57 - 2995.30] Speaker1: And
[2996.01 - 3000.39] Speaker1: um
[3000.70 - 3001.30] Speaker1: Yeah.
[3000.89 - 3001.28] Speaker2: Yeah.
[3001.30 - 3012.11] Speaker2: I'll do my homework because I know I'm ready before that. The meeting with the president will be as quick as possible. It will help me in the process. And I'll be back. I'll be back.
[3001.70 - 3001.89] Speaker1: you
[3011.36 - 3013.16] Speaker1: So it's going to start.
[3013.16 - 3013.55] Speaker2: you
[3013.66 - 3021.66] Speaker1: um
[3019.32 - 3019.55] Speaker2: you
[3021.93 - 3023.32] Speaker2: Thank you very much.
[3023.66 - 3025.66] Speaker1: .
[3025.91 - 3026.74] Speaker2: Yeah.
[3026.74 - 3027.72] Speaker1: Yeah.
[3028.09 - 3029.11] Speaker1: Shippur batalich.
[3029.74 - 3034.11] Speaker2: Yes.
[3033.49 - 3036.26] Speaker1: and people like you are people who can do it.
[3036.57 - 3037.57] Speaker2: Yeah.
[3038.36 - 3039.11] Speaker1: Till then, bye.
[3039.11 - 3039.51] Speaker2: you
